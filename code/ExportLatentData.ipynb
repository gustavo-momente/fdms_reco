{
 "metadata": {
  "name": "",
  "signature": "sha256:9b6920b1876568962a8c0e39934b09573c9794e89ad836677701d7ba85b3d5c0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!/usr/bin/python\n",
      "# -*- coding: utf-8 -*-\n",
      "\n",
      "__author__ = '3404199'\n",
      "\n",
      "import numpy as np\n",
      "import Parser\n",
      "import itertools\n",
      "import Tools\n",
      "from Models import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "datafile = r\"../ml-100k/u.data\"\n",
      "\n",
      "# Best config from GridSearch\n",
      "config = [10,20,0.1,0.1]\n",
      "\n",
      "# Now learn the model for the whole data\n",
      "model = SVDGD(datafile, epochs=config[0], nZ=config[1], lambda_4=config[2], learning_rate=config[3])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Global bias: {:1.3f}\".format(model.mi)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Global bias: 3.530\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "save_dir = \"../export_data\"\n",
      "if not os.path.isdir(save_dir):\n",
      "    os.makedirs(save_dir)\n",
      "# Export user_bias\n",
      "np.savetxt(\"{}/user_bias.csv\".format(save_dir),model.user_bias,delimiter=\",\")\n",
      "\n",
      "# Export item_bias\n",
      "np.savetxt(\"{}/item_bias.csv\".format(save_dir),model.item_bias,delimiter=\",\")\n",
      "\n",
      "# Export user_latent\n",
      "np.savetxt(\"{}/user_latent.csv\".format(save_dir),model.user_latent[1:,:],delimiter=\",\")\n",
      "\n",
      "# Export item_latent\n",
      "np.savetxt(\"{}/item_latent.csv\".format(save_dir),model.item_latent[1:,:],delimiter=\",\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.user_latent[1:,:].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "(943L, 20L)"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pairs_lt = Tools.folder2pairs(r\"../ml-100k/\")\n",
      "m_score = 0.0\n",
      "for pair in pairs_lt:\n",
      "    bias = Bias(Parser.MatrixParser.txttocsc(pair[0]), \"item_{}.png\".format(pair[2]), case='item')\n",
      "    score = bias.predict(Parser.MatrixParser.txttocsc(pair[1]))\n",
      "    print pair[2], score\n",
      "    m_score += score\n",
      "print \"Mean Item\", m_score/len(pairs_lt)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 1.03341137142\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.0304843172\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.01966297961\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.01687935065\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.02233512342\n",
        "Mean Item 1.02455462846\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pairs_lt = Tools.folder2pairs(r\"../ml-100k/\")\n",
      "m_score = 0.0\n",
      "for pair in pairs_lt:\n",
      "    bias = Bias(Parser.MatrixParser.txttocsc(pair[0]), \"item_{}.png\".format(pair[2]), case='user')\n",
      "    score = bias.predict(Parser.MatrixParser.txttocsc(pair[1]))\n",
      "    print pair[2], score\n",
      "    m_score += score\n",
      "print \"Mean user\", m_score/len(pairs_lt)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 1.06299512766\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.04674674923\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.0328964563\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.03665759713\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.03929235048\n",
        "Mean user 1.04371765616\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "C:\\Python27\\lib\\site-packages\\matplotlib\\pyplot.py:423: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_num_figures`).\n",
        "  max_open_warning, RuntimeWarning)\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "datafile = r\"../ml-100k/u.data\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "biasI = Bias(Parser.MatrixParser.txttocsc(datafile), \"tmp.png\", case='item')\n",
      "biasU = Bias(Parser.MatrixParser.txttocsc(datafile), \"tmp.png\", case='user')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.transpose(biasI.pred).shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "(1683L, 1L)"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "save_dir = \"../export_data\"\n",
      "# Export user_bias\n",
      "np.savetxt(\"{}/user_biasBasic.csv\".format(save_dir),np.transpose(biasU.pred),delimiter=\",\")\n",
      " \n",
      "# Export item_bias\n",
      "np.savetxt(\"{}/item_biasBasic.csv\".format(save_dir),np.transpose(biasI.pred),delimiter=\",\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}